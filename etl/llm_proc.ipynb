{
 "cells": [
  {
   "cell_type": "code",
   "id": "18d21a11a4172704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T19:17:47.556318Z",
     "start_time": "2025-03-24T19:17:47.553386Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T19:17:58.486614Z",
     "start_time": "2025-03-24T19:17:48.141769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fixando sementes para reprodutibilidade\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Se necessário, forçar algoritmos determinísticos:\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    ")\n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "model_name = \"aaditya/OpenBioLLM-Llama3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ],
   "id": "fb17c86f22adfba4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45eea520f1624f9c9ec74a12b50930e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T19:18:00.193242Z",
     "start_time": "2025-03-24T19:18:00.190774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ner_summary(text):\n",
    "    prompt = f\"Extrai entidades NER dos critério de forma estruturada:\\n\\n{text}\\n\\nOutput desejado em JSON. Deduplica os resultados se os mesmos estiverem escritos em duas línguas diferentes, Não repitas o prompt, retorna apenas o json final\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs, max_new_tokens=200, temperature=0.2)\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return result"
   ],
   "id": "de499f2df19e96f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T19:18:07.862285Z",
     "start_time": "2025-03-24T19:18:07.736650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Fixar sementes para reprodutibilidade\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# such as \"age\", \"ischemic_event\", \"onset_of_symptoms\", \"venous_access\", \"consent\", \"NIHSS\", etc, always\n",
    "def test_summary():\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "        You are an assistant specialized in extracting and summarizing inclusion criteria for clinical trials. From the following list of criteria, extract the main summarized criteria and return a JSON where a representative label associated to each criterion is corresponded to its summarized criterion (like 'representative label: criterion'). Use clear labels based in the corresponding criterion. If a criterion does not perfectly fit a known label, create an appropriate succinct label. Return only a complete and valid JSON, without any additional text or repetition of the prompt. if any criterion is in portuguese, translate it to english before extracting the 'label: criterion' pair.\n",
    "        List of criteria:\n",
    "        [\"Age 18-80 years\", \"Have suffered an acute hemispheric ischemic stroke attributable to injury within the territory supplied by the Middle Cerebral Artery (MCA)\", \"Symptomatic arterial territory is recanalized at the time of randomization\", \"Onset of an acute ischemic stroke that can have full clinical, imagiological and bone marrow collection within 7 days after the onset of symptoms. Onset is defined as the time that the subject was last seen in a normal state, or bedtime for unwitnessed strokes occurring during sleep\", \"Have readily accessible peripheral venous access blood sampling\", \"Have the ability to understand the requirements of the study and be willing to provide written informed consent, as evidenced by signature on an informed consent document (which has been submitted and approved by the local Ethical Committee), and agree to perform the required assessments. In the event of incapacitated subjects, informed consent will be sought from a legally acceptable representative\", \"NIHSS of at least 6 at the time of study inclusion\"]\n",
    "        \\n\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=20000,\n",
    "        temperature=0.5,\n",
    "        do_sample=True\n",
    "    )\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extrair o JSON: remover tudo até \"Aswer:\" e o marcador \"END_JSON\"\n",
    "    marker = \"Aswer:\"\n",
    "    start_index = result.find(marker)\n",
    "    if start_index != -1:\n",
    "        json_str = result[start_index + len(marker):].strip()\n",
    "    else:\n",
    "        json_str = result.strip()\n",
    "\n",
    "    # Remover o marcador final \"END_JSON\", se presente\n",
    "    end_marker = \"END_JSON\"\n",
    "    if json_str.endswith(end_marker):\n",
    "        json_str = json_str[:-len(end_marker)].strip()\n",
    "\n",
    "    # Tentar interpretar o restante como JSON\n",
    "    try:\n",
    "        json_obj = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Se ocorrer erro, pode-se logar ou retornar o texto bruto para análise\n",
    "        print(\"Erro ao interpretar JSON:\", e)\n",
    "        json_obj = json_str\n",
    "\n",
    "    return json_obj, output\n",
    "\n",
    "# Testa a função\n",
    "resultado_json, _ = test_summary()\n",
    "print(resultado_json)"
   ],
   "id": "8971a50d38435b01",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 59\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m json_obj, output\n\u001B[32m     58\u001B[39m \u001B[38;5;66;03m# Testa a função\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m resultado_json, _ = \u001B[43mtest_summary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28mprint\u001B[39m(resultado_json)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 27\u001B[39m, in \u001B[36mtest_summary\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     17\u001B[39m prompt = (\n\u001B[32m     18\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[33;03m    You are an assistant specialized in extracting and summarizing inclusion criteria for clinical trials. From the following list of criteria, extract the main summarized criteria and return a JSON where a representative label associated to each criterion is corresponded to its summarized criterion (like 'representative label: criterion'). Use clear labels based in the corresponding criterion. If a criterion does not perfectly fit a known label, create an appropriate succinct label. Return only a complete and valid JSON, without any additional text or repetition of the prompt. if any criterion is in portuguese, translate it to english before extracting the 'label: criterion' pair.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     24\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     25\u001B[39m )\n\u001B[32m     26\u001B[39m inputs = tokenizer(prompt, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m).to(\u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m output = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m20000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     32\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m result = tokenizer.decode(output[\u001B[32m0\u001B[39m], skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# Extrair o JSON: remover tudo até \"Aswer:\" e o marcador \"END_JSON\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/transformers/generation/utils.py:2223\u001B[39m, in \u001B[36mGenerationMixin.generate\u001B[39m\u001B[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[39m\n\u001B[32m   2215\u001B[39m     input_ids, model_kwargs = \u001B[38;5;28mself\u001B[39m._expand_inputs_for_generation(\n\u001B[32m   2216\u001B[39m         input_ids=input_ids,\n\u001B[32m   2217\u001B[39m         expand_size=generation_config.num_return_sequences,\n\u001B[32m   2218\u001B[39m         is_encoder_decoder=\u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder,\n\u001B[32m   2219\u001B[39m         **model_kwargs,\n\u001B[32m   2220\u001B[39m     )\n\u001B[32m   2222\u001B[39m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2223\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2224\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2225\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2226\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2227\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2228\u001B[39m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m=\u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2229\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2230\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2231\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2233\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001B[32m   2234\u001B[39m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[32m   2235\u001B[39m     beam_scorer = BeamSearchScorer(\n\u001B[32m   2236\u001B[39m         batch_size=batch_size,\n\u001B[32m   2237\u001B[39m         num_beams=generation_config.num_beams,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2242\u001B[39m         max_length=generation_config.max_length,\n\u001B[32m   2243\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/transformers/generation/utils.py:3211\u001B[39m, in \u001B[36mGenerationMixin._sample\u001B[39m\u001B[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[39m\n\u001B[32m   3208\u001B[39m model_inputs.update({\u001B[33m\"\u001B[39m\u001B[33moutput_hidden_states\u001B[39m\u001B[33m\"\u001B[39m: output_hidden_states} \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;28;01melse\u001B[39;00m {})\n\u001B[32m   3210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_prefill:\n\u001B[32m-> \u001B[39m\u001B[32m3211\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   3212\u001B[39m     is_prefill = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   3213\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:842\u001B[39m, in \u001B[36mLlamaForCausalLM.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m    841\u001B[39m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m842\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    844\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    845\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    846\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    847\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    848\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    849\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    850\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    851\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    852\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    853\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    854\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    856\u001B[39m hidden_states = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    857\u001B[39m \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/transformers/models/llama/modeling_llama.py:550\u001B[39m, in \u001B[36mLlamaModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001B[39m\n\u001B[32m    547\u001B[39m     use_cache = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    549\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m550\u001B[39m     inputs_embeds = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membed_tokens\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    552\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mand\u001B[39;00m past_key_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    553\u001B[39m     past_key_values = DynamicCache()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001B[39m, in \u001B[36mEmbedding.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    189\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m190\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ptoolctex/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001B[39m, in \u001B[36membedding\u001B[39m\u001B[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[39m\n\u001B[32m   2545\u001B[39m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[32m   2546\u001B[39m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[32m   2547\u001B[39m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[32m   2548\u001B[39m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[32m   2549\u001B[39m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[32m   2550\u001B[39m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[32m-> \u001B[39m\u001B[32m2551\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:57:27.046675Z",
     "start_time": "2025-03-23T15:57:27.044474Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7e8ce4b87697842",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12840,    374,   1370,  68323,    309,    337,     30, 128001]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:46:02.283403Z",
     "start_time": "2025-03-23T15:46:02.239786Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_parquet('../sources/full_df.parquet')",
   "id": "a8915f70d5966d8a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:46:03.284500Z",
     "start_time": "2025-03-23T15:46:03.277623Z"
    }
   },
   "cell_type": "code",
   "source": "df.sample(5)",
   "id": "f0d23f7dddec729e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             eudract_nr                                 Sponsor  \\\n",
       "1179     2015-003471-30                        Ipsen Innovation   \n",
       "2642  2024-512912-23-00  Bluepharma Industria Farmaceutica S.A.   \n",
       "691      2010-024252-29             Boehringer Ingelheim France   \n",
       "4529               None                              EMD Serono   \n",
       "2295  2023-505061-82-00                                  AbbVie   \n",
       "\n",
       "                                     therapeutic_area  Gender_F  Gender_M  \\\n",
       "1179                          Not possible to specify      True      True   \n",
       "2642                      [\"Not possible to specify\"]      True      True   \n",
       "691   Diseases [C] - Respiratory Tract Diseases [C08]      True      True   \n",
       "4529                                             None      True      True   \n",
       "2295                                             None      True      True   \n",
       "\n",
       "                                          inclusion_crt  \\\n",
       "1179  [\"The following inclusion criteria will be ass...   \n",
       "2642                                               None   \n",
       "691   [\"Age >= 40 years;\", \"IPF diagnosed, according...   \n",
       "4529                                               None   \n",
       "2295                                               None   \n",
       "\n",
       "                                          exclusion_crt  \\\n",
       "1179  [\"The following exclusion criteria will be ass...   \n",
       "2642                                               None   \n",
       "691   [\"Laboratory parameters (AST, ALT > 1.5 x ULN;...   \n",
       "4529                                               None   \n",
       "2295                                               None   \n",
       "\n",
       "                     status  \\\n",
       "1179              Completed   \n",
       "2642                      2   \n",
       "691               Completed   \n",
       "4529              COMPLETED   \n",
       "2295  ACTIVE_NOT_RECRUITING   \n",
       "\n",
       "                                                    url  \\\n",
       "1179  https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "2642  https://euclinicaltrials.eu/ctis-public-api/re...   \n",
       "691   https://www.clinicaltrialsregister.eu/ctr-sear...   \n",
       "4529                                               None   \n",
       "2295                                               None   \n",
       "\n",
       "     trial_design.Comparator_description  ...  \\\n",
       "1179                                None  ...   \n",
       "2642                                None  ...   \n",
       "691                                 None  ...   \n",
       "4529                                None  ...   \n",
       "2295                                None  ...   \n",
       "\n",
       "                                                  title         Protocol  \\\n",
       "1179  A Phase III, Multicentre, Randomised, Double B...         CONTENT1   \n",
       "2642  Bioequivalence of Lenvatinib 10 mg Capsules ve...  BLCL-LEN-FDA-02   \n",
       "691   A 52 Weeks, Double Blind, Randomized, Placebo-...          1199.34   \n",
       "4529  A Phase III, Randomized, Double-blind, Placebo...        ORACLE MS   \n",
       "2295  A Phase 3 Randomized, Placebo-controlled, Doub...            Up-AA   \n",
       "\n",
       "      start_date  trial_Early_Phase_I  trial_Phase_I  trial_Phase_II  \\\n",
       "1179  2016-03-31                False          False           False   \n",
       "2642  2024-06-21                False           True           False   \n",
       "691   2011-03-15                False          False           False   \n",
       "4529  2008-12-31                False          False           False   \n",
       "2295  2023-10-11                False          False           False   \n",
       "\n",
       "      trial_Phase_III  trial_Phase_IV  \\\n",
       "1179             True           False   \n",
       "2642            False           False   \n",
       "691              True           False   \n",
       "4529             True           False   \n",
       "2295             True           False   \n",
       "\n",
       "                                      condition  masking_OPEN  \n",
       "1179  Urinary Incontinence | Overactive Bladder         False  \n",
       "2642                       No medical condition          None  \n",
       "691                          Pulmonary Fibrosis         False  \n",
       "4529                         Multiple Sclerosis         False  \n",
       "2295                            Alopecia Areata         False  \n",
       "\n",
       "[5 rows x 80 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eudract_nr</th>\n",
       "      <th>Sponsor</th>\n",
       "      <th>therapeutic_area</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>inclusion_crt</th>\n",
       "      <th>exclusion_crt</th>\n",
       "      <th>status</th>\n",
       "      <th>url</th>\n",
       "      <th>trial_design.Comparator_description</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>start_date</th>\n",
       "      <th>trial_Early_Phase_I</th>\n",
       "      <th>trial_Phase_I</th>\n",
       "      <th>trial_Phase_II</th>\n",
       "      <th>trial_Phase_III</th>\n",
       "      <th>trial_Phase_IV</th>\n",
       "      <th>condition</th>\n",
       "      <th>masking_OPEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>2015-003471-30</td>\n",
       "      <td>Ipsen Innovation</td>\n",
       "      <td>Not possible to specify</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"The following inclusion criteria will be ass...</td>\n",
       "      <td>[\"The following exclusion criteria will be ass...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>A Phase III, Multicentre, Randomised, Double B...</td>\n",
       "      <td>CONTENT1</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Urinary Incontinence | Overactive Bladder</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>2024-512912-23-00</td>\n",
       "      <td>Bluepharma Industria Farmaceutica S.A.</td>\n",
       "      <td>[\"Not possible to specify\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>https://euclinicaltrials.eu/ctis-public-api/re...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Bioequivalence of Lenvatinib 10 mg Capsules ve...</td>\n",
       "      <td>BLCL-LEN-FDA-02</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No medical condition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2010-024252-29</td>\n",
       "      <td>Boehringer Ingelheim France</td>\n",
       "      <td>Diseases [C] - Respiratory Tract Diseases [C08]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Age &gt;= 40 years;\", \"IPF diagnosed, according...</td>\n",
       "      <td>[\"Laboratory parameters (AST, ALT &gt; 1.5 x ULN;...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>https://www.clinicaltrialsregister.eu/ctr-sear...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>A 52 Weeks, Double Blind, Randomized, Placebo-...</td>\n",
       "      <td>1199.34</td>\n",
       "      <td>2011-03-15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Pulmonary Fibrosis</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>None</td>\n",
       "      <td>EMD Serono</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>A Phase III, Randomized, Double-blind, Placebo...</td>\n",
       "      <td>ORACLE MS</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Multiple Sclerosis</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>2023-505061-82-00</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ACTIVE_NOT_RECRUITING</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>A Phase 3 Randomized, Placebo-controlled, Doub...</td>\n",
       "      <td>Up-AA</td>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alopecia Areata</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:46:04.995098Z",
     "start_time": "2025-03-23T15:46:04.533305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplica função ao dataframe original, criando novas colunas automaticamente\n",
    "get_ner_summary('[\"Age 18-80 years\", \"Have suffered an acute hemispheric ischemic stroke attributable to injury within the territory supplied by the Middle Cerebral Artery (MCA)\", \"Symptomatic arterial territory is recanalyzed at the time of randomization\", \"Onset of an acute ischemic stroke that can have full clinical, imagiological and bone marrow collection within 7 days after the onset of symptoms. Onset is defined as the time that the subject was last seen in a normal state, or bedtime for unwitnessed strokes occurring during sleep\", \"Have readily accessible peripheral venous access blood sampling\", \"Have the ability to understand the requirements of the study and be willing to provide written informed consent, as evidenced by signature on an informed consent document (which has been submitted and approved by the local Ethical Committee),and agree to perform the required assessments. In the event of incapacitated subjects, informed consent will be sought from a legally acceptable representative\", \"NIHSS of at least 6 at the time of study inclusion\"]')"
   ],
   "id": "d19a9af2070663b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Extrai entidades NER dos critério de forma estruturada:\\n\\n[\"Age 18-80 years\", \"Have suffered an acute hemispheric ischemic stroke attributable to injury within the territory supplied by the Middle Cerebral Artery (MCA)\", \"Symptomatic arterial territory is recanalyzed at the time of randomization\", \"Onset of an acute ischemic stroke that can have full clinical, imagiological and bone marrow collection within 7 days after the onset of symptoms. Onset is defined as the time that the subject was last seen in a normal state, or bedtime for unwitnessed strokes occurring during sleep\", \"Have readily accessible peripheral venous access blood sampling\", \"Have the ability to understand the requirements of the study and be willing to provide written informed consent, as evidenced by signature on an informed consent document (which has been submitted and approved by the local Ethical Committee),and agree to perform the required assessments. In the event of incapacitated subjects, informed consent will be sought from a legally acceptable representative\", \"NIHSS of at least 6 at the time of study inclusion\"]\\n\\nOutput desejado em JSON. Deduplica os resultados se os mesmos estiverem escritos em duas línguas diferentes, Não repitas o prompt, retorna apenas o json final.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:30:48.287728Z",
     "start_time": "2025-03-23T15:30:48.285337Z"
    }
   },
   "cell_type": "code",
   "source": "df['inclusion_crt'].head(5)",
   "id": "2421487169f56171",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2851                                                 None\n",
       "2788                                                 None\n",
       "2967                                                 None\n",
       "2742    [\"Age 18-80 years\", \"Have suffered an acute he...\n",
       "2749                                                 None\n",
       "Name: inclusion_crt, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Expandir resultados em novas colunas\n",
    "df_expanded = pd.json_normalize(df['ner_result'])\n",
    "df_final = pd.concat([df, df_expanded], axis=1)\n",
    "\n",
    "df_final.to_csv('resultado_final.csv', index=False)"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
